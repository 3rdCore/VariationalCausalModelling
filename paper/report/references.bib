
@misc{mahajan_zero-shot_2024,
	title = {Zero-{Shot} {Learning} of {Causal} {Models}},
	url = {http://arxiv.org/abs/2410.06128},
	doi = {10.48550/arXiv.2410.06128},
	abstract = {With the increasing acquisition of datasets over time, we now have access to precise and varied descriptions of the world, capturing all sorts of phenomena. These datasets can be seen as empirical observations of unknown causal generative processes, which can commonly be described by Structural Causal Models (SCMs). Recovering these causal generative processes from observations poses formidable challenges, and often require to learn a specific generative model for each dataset. In this work, we propose to learn a {\textbackslash}emph\{single\} model capable of inferring in a zero-shot manner the causal generative processes of datasets. Rather than learning a specific SCM for each dataset, we enable the Fixed-Point Approach (FiP) proposed in{\textasciitilde}{\textbackslash}cite\{scetbon2024fip\}, to infer the generative SCMs conditionally on their empirical representations. More specifically, we propose to amortize the learning of a conditional version of FiP to infer generative SCMs from observations and causal structures on synthetically generated datasets. We show that our model is capable of predicting in zero-shot the true generative SCMs, and as a by-product, of (i) generating new dataset samples, and (ii) inferring intervened ones. Our experiments demonstrate that our amortized procedure achieves performances on par with SoTA methods trained specifically for each dataset on both in and out-of-distribution problems. To the best of our knowledge, this is the first time that SCMs are inferred in a zero-shot manner from observations, paving the way for a paradigmatic shift towards the assimilation of causal knowledge across datasets.},
	urldate = {2024-10-22},
	publisher = {arXiv},
	author = {Mahajan, Divyat and Gladrow, Jannes and Hilmkil, Agrin and Zhang, Cheng and Scetbon, Meyer},
	month = oct,
	year = {2024},
	note = {arXiv:2410.06128},
	keywords = {Computer Science - Machine Learning, notion, Statistics - Machine Learning},
	file = {Mahajan et al. - 2024 - Zero-Shot Learning of Causal Models.pdf:C\:\\Users\\Tom\\Zotero\\storage\\2CKHUH4P\\Mahajan et al. - 2024 - Zero-Shot Learning of Causal Models.pdf:application/pdf},
}
@misc{brouillard2020differentiablecausaldiscoveryinterventional,
      title={Differentiable Causal Discovery from Interventional Data},
      author={Philippe Brouillard and Sébastien Lachapelle and Alexandre Lacoste and Simon Lacoste-Julien and Alexandre Drouin},
      year={2020},
      eprint={2007.01754},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2007.01754},
}
@INPROCEEDINGS {SCMVAE,
author = { Komanduri, Aneesh and Wu, Yongkai and Huang, Wen and Chen, Feng and Wu, Xintao },
booktitle = { 2022 IEEE International Conference on Big Data (Big Data) },
title = {{ SCM-VAE: Learning Identifiable Causal Representations via Structural Knowledge }},
year = {2022},
volume = {},
ISSN = {},
pages = {1014-1023},
abstract = { The goal of causal representation learning is to map low-level observations to high-level causal concepts to learn interpretable and robust representations for various downstream tasks. Latent variable models such as the variational autoencoder (VAE) are frequently leveraged to learn disentangled representations. However, there are often complex non-linear causal relationships underlying the observed data that cannot be captured through disentangled representations or linear dependence assumptions. Further, an independent conditional prior assumption can make learning causal dependencies in the latent space more challenging. We propose a framework, coined SCM-VAE, which uses apriori causal knowledge, a structural causal prior, and a non-linear additive noise structural causal model (SCM) to learn independent causal mechanisms and identifiable causal representations. We conduct theoretical analysis and perform experiments on synthetic and real-world datasets to show the improved quality of learned causal representations and robustness under interventions. },
keywords = {Representation learning;Additive noise;Big Data;Robustness;Task analysis},
doi = {10.1109/BigData55660.2022.10021114},
url = {https://doi.ieeecomputersociety.org/10.1109/BigData55660.2022.10021114},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month =Dec}

@INPROCEEDINGS{CausalVAE,
  author={Yang, Mengyue and Liu, Furui and Chen, Zhitang and Shen, Xinwei and Hao, Jianye and Wang, Jun},
  booktitle={2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  title={CausalVAE: Disentangled Representation Learning via Neural Structural Causal Models},
  year={2021},
  volume={},
  number={},
  pages={9588-9597},
  keywords={Analytical models;Directed acyclic graph;Computer vision;Semantics;Transforms;Benchmark testing;Data models},
  doi={10.1109/CVPR46437.2021.00947}}

@misc{lorch2022amortizedinferencecausalstructure,
      title={Amortized Inference for Causal Structure Learning},
      author={Lars Lorch and Scott Sussex and Jonas Rothfuss and Andreas Krause and Bernhard Schölkopf},
      year={2022},
      eprint={2205.12934},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2205.12934},
}
@misc{oord_neural_2018,
	title = {Neural {Discrete} {Representation} {Learning}},
	url = {http://arxiv.org/abs/1711.00937},
	doi = {10.48550/arXiv.1711.00937},
	abstract = {Learning useful representations without supervision remains a key challenge in machine learning. In this paper, we propose a simple yet powerful generative model that learns such discrete representations. Our model, the Vector Quantised-Variational AutoEncoder (VQ-VAE), differs from VAEs in two key ways: the encoder network outputs discrete, rather than continuous, codes; and the prior is learnt rather than static. In order to learn a discrete latent representation, we incorporate ideas from vector quantisation (VQ). Using the VQ method allows the model to circumvent issues of "posterior collapse" -- where the latents are ignored when they are paired with a powerful autoregressive decoder -- typically observed in the VAE framework. Pairing these representations with an autoregressive prior, the model can generate high quality images, videos, and speech as well as doing high quality speaker conversion and unsupervised learning of phonemes, providing further evidence of the utility of the learnt representations.},
	urldate = {2024-12-09},
	publisher = {arXiv},
	author = {Oord, Aaron van den and Vinyals, Oriol and Kavukcuoglu, Koray},
	month = may,
	year = {2018},
	note = {arXiv:1711.00937 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {Preprint PDF:C\:\\Users\\Tom\\Zotero\\storage\\X4AU4S9P\\Oord et al. - 2018 - Neural Discrete Representation Learning.pdf:application/pdf;Snapshot:C\:\\Users\\Tom\\Zotero\\storage\\8L3CKWPD\\1711.html:text/html},
}

@inproceedings{fajtl_latent_2020,
	title = {Latent {Bernoulli} {Autoencoder}},
	url = {https://proceedings.mlr.press/v119/fajtl20a.html},
	abstract = {In this work, we pose the question whether it is possible to design and train an autoencoder model in an end-to-end fashion to learn representations in the multivariate Bernoulli latent space, and achieve performance comparable with the state-of-the-art variational methods. Moreover, we investigate how to generate novel samples and perform smooth interpolation and attributes modification in the binary latent space. To meet our objective, we propose a simplified, deterministic model with a straight-through gradient estimator to learn the binary latents and show its competitiveness with the latest VAE methods. Furthermore, we propose a novel method based on a random hyperplane rounding for sampling and smooth interpolation in the latent space. Our method performs on a par or better than the current state-of-the-art methods on common CelebA, CIFAR-10 and MNIST datasets.},
	language = {en},
	urldate = {2024-12-10},
	booktitle = {Proceedings of the 37th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Fajtl, Jiri and Argyriou, Vasileios and Monekosso, Dorothy and Remagnino, Paolo},
	month = nov,
	year = {2020},
	note = {ISSN: 2640-3498},
	pages = {2964--2974},
	file = {Full Text PDF:C\:\\Users\\Tom\\Zotero\\storage\\RXHKQW56\\Fajtl et al. - 2020 - Latent Bernoulli Autoencoder.pdf:application/pdf;Supplementary PDF:C\:\\Users\\Tom\\Zotero\\storage\\WPMRMABI\\Fajtl et al. - 2020 - Latent Bernoulli Autoencoder.pdf:application/pdf},
}

@misc{scetbon_fip_2024,
	title = {{FiP}: a {Fixed}-{Point} {Approach} for {Causal} {Generative} {Modeling}},
	shorttitle = {{FiP}},
	url = {http://arxiv.org/abs/2404.06969},
	doi = {10.48550/arXiv.2404.06969},
	abstract = {Modeling true world data-generating processes lies at the heart of empirical science. Structural Causal Models (SCMs) and their associated Directed Acyclic Graphs (DAGs) provide an increasingly popular answer to such problems by defining the causal generative process that transforms random noise into observations. However, learning them from observational data poses an ill-posed and NP-hard inverse problem in general. In this work, we propose a new and equivalent formalism that does not require DAGs to describe them, viewed as fixed-point problems on the causally ordered variables, and we show three important cases where they can be uniquely recovered given the topological ordering (TO). To the best of our knowledge, we obtain the weakest conditions for their recovery when TO is known. Based on this, we design a two-stage causal generative model that first infers the causal order from observations in a zero-shot manner, thus by-passing the search, and then learns the generative fixed-point SCM on the ordered variables. To infer TOs from observations, we propose to amortize the learning of TOs on generated datasets by sequentially predicting the leaves of graphs seen during training. To learn fixed-point SCMs, we design a transformer-based architecture that exploits a new attention mechanism enabling the modeling of causal structures, and show that this parameterization is consistent with our formalism. Finally, we conduct an extensive evaluation of each method individually, and show that when combined, our model outperforms various baselines on generated out-of-distribution problems.},
	urldate = {2024-12-11},
	publisher = {arXiv},
	author = {Scetbon, Meyer and Jennings, Joel and Hilmkil, Agrin and Zhang, Cheng and Ma, Chao},
	month = apr,
	year = {2024},
	note = {arXiv:2404.06969 [cs]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Preprint PDF:C\:\\Users\\Tom\\Zotero\\storage\\GEEN8MJR\\Scetbon et al. - 2024 - FiP a Fixed-Point Approach for Causal Generative .pdf:application/pdf;Snapshot:C\:\\Users\\Tom\\Zotero\\storage\\8EEIGXLD\\2404.html:text/html},
}
@misc{fu2019cyclicalannealingschedulesimple,
      title={Cyclical Annealing Schedule: A Simple Approach to Mitigating KL Vanishing},
      author={Hao Fu and Chunyuan Li and Xiaodong Liu and Jianfeng Gao and Asli Celikyilmaz and Lawrence Carin},
      year={2019},
      eprint={1903.10145},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1903.10145},
}
@misc{hu_encoding_2023,
	title = {Encoding {Binary} {Concepts} in the {Latent} {Space} of {Generative} {Models} for {Enhancing} {Data} {Representation}},
	url = {http://arxiv.org/abs/2303.12255},
	doi = {10.48550/arXiv.2303.12255},
	abstract = {Binary concepts are empirically used by humans to generalize efficiently. And they are based on Bernoulli distribution which is the building block of information. These concepts span both low-level and high-level features such as "large vs small" and "a neuron is active or inactive". Binary concepts are ubiquitous features and can be used to transfer knowledge to improve model generalization. We propose a novel binarized regularization to facilitate learning of binary concepts to improve the quality of data generation in autoencoders. We introduce a binarizing hyperparameter \$r\$ in data generation process to disentangle the latent space symmetrically. We demonstrate that this method can be applied easily to existing variational autoencoder (VAE) variants to encourage symmetric disentanglement, improve reconstruction quality, and prevent posterior collapse without computation overhead. We also demonstrate that this method can boost existing models to learn more transferable representations and generate more representative samples for the input distribution which can alleviate catastrophic forgetting using generative replay under continual learning settings.},
	urldate = {2024-12-12},
	publisher = {arXiv},
	author = {Hu, Zizhao and Rostami, Mohammad},
	month = mar,
	year = {2023},
	note = {arXiv:2303.12255 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
	file = {Preprint PDF:C\:\\Users\\Tom\\Zotero\\storage\\M4ZEX7DJ\\Hu and Rostami - 2023 - Encoding Binary Concepts in the Latent Space of Ge.pdf:application/pdf;Snapshot:C\:\\Users\\Tom\\Zotero\\storage\\VDCNCKNL\\2303.html:text/html},
}


@inproceedings{faria_differentiable_2022,
	title = {Differentiable {Causal} {Discovery} {Under} {Latent} {Interventions}},
	url = {https://proceedings.mlr.press/v177/faria22a.html},
	abstract = {Recent work has shown promising results in causal discovery by leveraging interventional data with gradient-based methods, even when the intervened variables are unknown. However, previous work assumes that the correspondence between samples and interventions is known, which is often unrealistic. We envision a scenario with an extensive dataset sampled from multiple intervention distributions and one observation distribution, but where we do not know which distribution originated each sample and how the intervention affected the system, {\textbackslash}textit\{i.e.\}, interventions are entirely latent. We propose a method based on neural networks and variational inference that addresses this scenario by framing it as learning a shared causal graph among a infinite mixture (under a Dirichlet process prior) of intervention structural causal models . Experiments with synthetic and real data show that our approach and its semi-supervised variant are able to discover causal relations in this challenging scenario.},
	language = {en},
	urldate = {2024-12-13},
	booktitle = {Proceedings of the {First} {Conference} on {Causal} {Learning} and {Reasoning}},
	publisher = {PMLR},
	author = {Faria, Gonçalo Rui Alves and Martins, Andre and Figueiredo, Mario A. T.},
	month = jun,
	year = {2022},
	note = {ISSN: 2640-3498},
	pages = {253--274},
	file = {Full Text PDF:C\:\\Users\\Tom\\Zotero\\storage\\H3FQDRHH\\Faria et al. - 2022 - Differentiable Causal Discovery Under Latent Inter.pdf:application/pdf},
}

@book{Pearl_2009, place={Cambridge}, edition={2}, title={Causality}, publisher={Cambridge University Press}, author={Pearl, Judea}, year={2009}}

@misc{kingma2022autoencodingvariationalbayes,
      title={Auto-Encoding Variational Bayes},
      author={Diederik P Kingma and Max Welling},
      year={2022},
      eprint={1312.6114},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1312.6114},
}
@misc{jang2017categoricalreparameterizationgumbelsoftmax,
      title={Categorical Reparameterization with Gumbel-Softmax},
      author={Eric Jang and Shixiang Gu and Ben Poole},
      year={2017},
      eprint={1611.01144},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1611.01144},
}
@misc{chevalley2024derivingcausalordersinglevariable,
      title={Deriving Causal Order from Single-Variable Interventions: Guarantees and Algorithm},
      author={Mathieu Chevalley and Patrick Schwab and Arash Mehrjou},
      year={2024},
      eprint={2405.18314},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2405.18314},
}
